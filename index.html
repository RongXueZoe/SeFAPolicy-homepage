<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="Imitation Learning, Robot Manipulation, Visuomotor Policy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-2J8N1TPPE4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-2J8N1TPPE4');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/robot.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://rongxuezoe.github.io">Rong Xue</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="https://pointscoder.github.io/">Jiageng Mao</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="https://robo-alex.github.io/">Mingtong Zhang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yuewang.xyz/">Yue Wang</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Southern California</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/RongXueZoe/SeFA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/folders/1aHRAxm16WAsKEIOiSfy66p29jOTf0GQS?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
        <b>SeFA Policy</b> is a visual imitation learning algorithm that utilizes rectified 
        flow with selective alignment, achieving superior effectiveness in diverse simulation 
        and real-world tasks, with a significant inference acceleration.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">
        <b>Real Robot Demonstration</b>
      </h2>
    </div>
    <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-3">
            <h2 class="subtitle">Rice Pouring</h2>
            <video poster="" id="pour" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pour.MOV"
                  type="video/mp4">
            </video>
          </div>
          <div class="column is-3">
            <h2 class="subtitle">Knob Pull</h2>
            <video poster="" id="pull" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pull.mov"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3">
            <h2 class="subtitle">Coffee Bean Sweeping</h2>
            <video poster="" id="sweep" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/sweep.MOV"
                      type="video/mp4">
            </video>
          </div>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column is-3">
            <h2 class="subtitle">Drawer Close</h2>
            <video poster="" id="push" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/push.MOV"
                  type="video/mp4">
            </video>
          </div>
          <div class="column is-3">
            <h2 class="subtitle">Moving Object Picking</h2>
            <video poster="" id="moving-duck" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/floating_duck.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="column is-3">
            <h2 class="subtitle">Putting Apple in the Bowl</h2>
            <video poster="" id="apple" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/apple.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>    </div>
  </div>
</div>
</section>

<br></br>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">
        <b>Comparison with Baseline</b>
      </h2>
    </div>
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-4">
          <h2 class="subtitle">Flower Insertion (ours)</h2>
          <video poster="" id="flower" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/flower.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="column is-4">
          <h2 class="subtitle">Flower Insertion (baseline)</h2>
          <video poster="" id="flower" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dp_x16.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-4">
          <h2 class="subtitle">Rice Pouring (ours)</h2>
          <video poster="" id="pour" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pour.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="column is-4">
          <h2 class="subtitle">Rice Pouring (baseline)</h2>
          <video poster="" id="pour_dp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pour_dp.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-4">
          <h2 class="subtitle">Drawer Close (ours)</h2>
          <video poster="" id="push" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/push.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="column is-4">
          <h2 class="subtitle">Drawer Close (baseline)</h2>
          <video poster="" id="push_dp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/push_dp.MOV"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning relies on accurate action predictions and fast inference to 
            successfully perform complicated real-world tasks.
            Generative modeling techniques such as Diffusion Policy[1] 
            have recently achieved strong performance in complex manipulation tasks, but their 
            reliance on multi-step iterative denoising makes them computationally expensive 
            and unsuitable for real-time control. Flow-based models have emerged as a promising 
            alternative, enabling fewer-step action generation and 
            rectification[2] by transporting nearly straight from noise to 
            action space, thus significantly reducing inference latency.
          <!-- </p>
          <p> -->
            Despite the efficiency, few-step sampling introduces discretization error, and 
            rectification introduces inconsistency between observation and action during 
            distillation. 
            When applying rectification, the reflow policy[2] is trained upon 
            the noise-action pairs generated by a well-trained policy. However, the generated 
            actions are not the same as ground-truth actions, i.e., the generated action and 
            visual observation pair could not exactly match. In terms of diffusion-based 
            models, the predicted action is distinct from the actions reflected in the visual 
            condition.
            Such inconsistency might be tolerable in image generation where perceptual 
            similarity suffices, but in robotic control, even minor inconsistencies between 
            observations and actions can accumulate and lead to task failures. This 
            distillation-induced inconsistency therefore represents a fundamental barrier to 
            deploying flow-based policies in effective real-time visuomotor control.
            
          </p>
          <p>
            To overcome this limitation, we propose Selective Flow Alignment (SeFA), a 
            flow-based visuomotor policy with a selective alignment strategy. The straight 
            paths in flow-based models are computationally efficient because they can be sampled 
            in a few or even one step. However, the straightening process[2] 
            often accumulates errors from the base model, which leads to the observation–action 
            inconsistency. SeFA leverages expert demonstrations to align the sampling paths with 
            observations while maintaining the straightness of the paths.
            Crucially, this alignment is applied in a selective manner, preserving action 
            diversity and multimodality while eliminating harmful mismatches. 
            By combining efficiency in straight sampling paths with observation-consistent 
            alignment, SeFA Policy enables one-step action synthesis that is both fast and reliable for 
            real-time visuomotor control.
          </p>
          <p>
            Leveraging nearly straight flows, SeFA Policy achieves high accuracy with just a 
            single denoising step. To evaluate the effectiveness of SeFA Policy, we conducted 
            extensive experiments across both simulated and real-world tasks. Results show that 
            our method matches or surpasses the performance of state-of-the-art diffusion-based 
            methods while while offering greater simplicity and computational efficiency. 
            Compared to Diffusion Policy, which involves numerous iterative steps and incurs 
            significant computational overhead, our approach offers a streamlined and scalable 
            solution for real-time visuomotor policy learning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/overview.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
        We train a visuomotor policy in an iterative manner to transport straight between 
        noise distribution and target action space, hence enabling lightning one-step 
        sampling during inference. The action flow is selectively \textit{aligned} with 
        observations, lowering the potential accumulated error brought by multiple reflows.
      </h2>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      [1] Chi C, Feng S, Du Y, et al. Diffusion Policy: Visuomotor Policy Learning via Action Diffusion[C]//Robotics: Science and Systems. 2023.
      [2] Liu X, Gong C, Liu Q. Flow straight and fast: Learning to generate and transfer data with rectified flow[J]. arXiv preprint arXiv:2209.03003, 2022.
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/???.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/rongxuezoe" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
